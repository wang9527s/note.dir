
```cpp
#ifndef  __KAFKA_CONSUMER_H
#define  __KAFKA_CONSUMER_H

#include <string>
#include <iostream>
#include "kafka/rdkafkacpp.h"

#ifdef _MSC_VER
#include <atltime.h>
#elif _AIX
#include <unistd.h>
#else
#include <getopt.h>
#include <unistd.h>
#endif

class KafkaConsumer :public RdKafka::RebalanceCb, public RdKafka::EventCb
{
public:
    KafkaConsumer();
    bool Init(const char*  topic, const char* broker, const char* group_id);
    void DoConsumeMsg();
    void Destroy();
    void MsgConsume(RdKafka::Message* message);
public:
    void event_cb(RdKafka::Event &event);
    void rebalance_cb(RdKafka::KafkaConsumer *consumer,
        RdKafka::ErrorCode err,
        std::vector<RdKafka::TopicPartition*> &partitions);
private:
    std::string mTopic;
    std::string mBroker;
private:
    RdKafka::KafkaConsumer* mConsumer;
};
#endif
```
```cpp
#include "KafkaConsumer.h"

KafkaConsumer::KafkaConsumer()
{
    mConsumer = NULL;
}

bool KafkaConsumer::Init(const char*  topic, const char* broker, const char* group_id)
{
    std::string errstr;
    std::vector<std::string> topics;
    RdKafka::Conf *conf = RdKafka::Conf::create(RdKafka::Conf::CONF_GLOBAL);
    RdKafka::Conf *tconf = RdKafka::Conf::create(RdKafka::Conf::CONF_TOPIC);
    conf->set("rebalance_cb", (RdKafka::RebalanceCb*)this, errstr);

    if (conf->set("group.id", group_id, errstr) != RdKafka::Conf::CONF_OK) {
        std::cerr << errstr << std::endl;
        return false;
    }
    topics.push_back(topic);
    conf->set("metadata.broker.list", broker, errstr);

    conf->set("event_cb", (RdKafka::EventCb*)this, errstr);
    conf->set("default_topic_conf", tconf, errstr);
    delete tconf;

    /*
    * Create consumer using accumulated global configuration.
    */
    mConsumer = RdKafka::KafkaConsumer::create(conf, errstr);
    if (!mConsumer) {
        std::cerr << "Failed to create consumer: " << errstr << std::endl;
        return false;
    }

    delete conf;

    std::cout << "% Created consumer " << mConsumer->name() << std::endl;


    /*
    * Subscribe to topics
    */
    RdKafka::ErrorCode err = mConsumer->subscribe(topics);
    if (err) {
        std::cerr << "Failed to subscribe to " << topics.size() << " topics: "
            << RdKafka::err2str(err) << std::endl;
        return false;
    }
    return true;
}

void KafkaConsumer::DoConsumeMsg()
{
    while (1) {
        RdKafka::Message *msg = mConsumer->consume(1000);
        MsgConsume(msg);
        delete msg;
    }
}

void KafkaConsumer::event_cb(RdKafka::Event &event)
{
    switch (event.type())
    {
    case RdKafka::Event::EVENT_ERROR:
        std::cerr << "ERROR (" << RdKafka::err2str(event.err()) << "): " <<
            event.str() << std::endl;
        if (event.err() == RdKafka::ERR__ALL_BROKERS_DOWN)
            ;// run = false;
        break;

    case RdKafka::Event::EVENT_STATS:
        std::cerr << "\"STATS\": " << event.str() << std::endl;
        break;

    case RdKafka::Event::EVENT_LOG:
        fprintf(stderr, "LOG-%i-%s: %s\n",
            event.severity(), event.fac().c_str(), event.str().c_str());
        break;

    case RdKafka::Event::EVENT_THROTTLE:
        std::cerr << "THROTTLED: " << event.throttle_time() << "ms by " <<
            event.broker_name() << " id " << (int)event.broker_id() << std::endl;
        break;

    default:
        std::cerr << "EVENT " << event.type() <<
            " (" << RdKafka::err2str(event.err()) << "): " <<
            event.str() << std::endl;
        break;
    }
}

void KafkaConsumer::rebalance_cb(RdKafka::KafkaConsumer *consumer,
    RdKafka::ErrorCode err,
    std::vector<RdKafka::TopicPartition*> &partitions)
{
    std::cerr << "RebalanceCb: " << RdKafka::err2str(err) << ": ";

    //part_list_print(partitions);

    if (err == RdKafka::ERR__ASSIGN_PARTITIONS) {
        consumer->assign(partitions);
        //partition_cnt = (int)partitions.size();
    }
    else {
        consumer->unassign();
        //partition_cnt = 0;
    }
    //eof_cnt = 0;
}

void KafkaConsumer::MsgConsume(RdKafka::Message* message)
{
    switch (message->err()) {
    case RdKafka::ERR__TIMED_OUT:
        break;

    case RdKafka::ERR_NO_ERROR:
        /* Real message */
            printf("%.*s\n",
                static_cast<int>(message->len()),
                static_cast<const char *>(message->payload()));
        break;

    case RdKafka::ERR__PARTITION_EOF:
        /* Last message */
        //if (exit_eof && ++eof_cnt == partition_cnt) {
        //  std::cerr << "%% EOF reached for all " << partition_cnt <<
        //      " partition(s)" << std::endl;
        //  //run = false;
        //}
        break;

    case RdKafka::ERR__UNKNOWN_TOPIC:
    case RdKafka::ERR__UNKNOWN_PARTITION:
        std::cerr << "Consume failed: " << message->errstr() << std::endl;
        //run = false;
        break;

    default:
        /* Errors */
        std::cerr << "Consume failed: " << message->errstr() << std::endl;
        //run = false;
    }
}

void KafkaConsumer::Destroy()
{
    if (mConsumer)
    {
        delete mConsumer;
        mConsumer = NULL;
    }
}

```
```cpp

void TestConsumer()//最好把此函数也封装提取成一个接口
{
    KafkaConsumer consumer;
    const char* brokers = "127.0.0.1:9000";
    const char* topic = "TOPIC_TEST";
    if (!consumer.Init(topic, brokers,"0"))
    {
        return;
    }
    /*
    * Read messages from stdin and produce to broker.
    */
    consumer.DoConsumeMsg();
    consumer.Destroy();
}

```

